"""SVD (Stable Video Diffusion) backend — image-to-video local generation."""
from __future__ import annotations

import gc
import logging
import time
from pathlib import Path
from typing import List, Optional, Tuple

from backend.services.prompt.types import ComposedPrompt
from backend.services.video.backends.base import VideoBackend
from backend.services.video.types import VideoClip

logger = logging.getLogger("beat_studio.video.svd")

_SUPPORTED_STYLES = {
    "cinematic", "photorealistic", "abstract", "oil_painting", "watercolor",
}
_DEFAULT_MODEL_PATH = "backend/models/svd/svd_xt.safetensors"
_VRAM_GB = 7.5
_COST_PER_SCENE_USD = 0.0


class SVDBackend(VideoBackend):
    """Stable Video Diffusion local backend (image-to-video).

    Best for: Animating a still key frame generated by SDXL.
    VRAM: ~7.5GB
    Cost: Free (local GPU)

    Use case: Generate SDXL key frame → animate with SVD → assemble clips.
    """

    def __init__(self, model_path: Optional[str] = None):
        self._model_path = Path(model_path or _DEFAULT_MODEL_PATH)
        self._pipeline = None

    def name(self) -> str:
        return "svd"

    def vram_required_gb(self) -> float:
        return _VRAM_GB

    def supports_style(self, style: str) -> bool:
        return style in _SUPPORTED_STYLES

    def is_available(self) -> bool:
        return self._model_path.exists()

    def estimated_time_per_scene(self, resolution: Tuple[int, int] = (1024, 576)) -> float:
        return 45.0  # ~45s for 25 frames at 1024×576

    def estimated_cost_per_scene(self) -> float:
        return _COST_PER_SCENE_USD

    def generate_clip(
        self, prompt: ComposedPrompt, duration_sec: float,
        resolution: Tuple[int, int], fps: int = 8, seed: int = -1,
    ) -> VideoClip:
        t0 = time.time()
        out_path = self._run_pipeline(prompt, duration_sec, resolution, fps, seed)
        return VideoClip(
            file_path=out_path, duration_sec=duration_sec,
            width=resolution[0], height=resolution[1], fps=fps,
            scene_index=-1, backend_used=self.name(),
            generation_time_sec=time.time() - t0, cost_usd=0.0,
        )

    def generate_batch(
        self, prompts: List[ComposedPrompt], durations: List[float],
        resolution: Tuple[int, int], fps: int = 8,
    ) -> List[VideoClip]:
        return [self.generate_clip(p, d, resolution, fps) for p, d in zip(prompts, durations)]

    def kill(self) -> None:
        del self._pipeline
        self._pipeline = None
        gc.collect()
        try:
            import torch
            torch.cuda.empty_cache()
        except Exception:
            pass

    def _run_pipeline(
        self, prompt: ComposedPrompt, duration_sec: float,
        resolution: Tuple[int, int], fps: int, seed: int,
    ) -> str:
        raise NotImplementedError("SVD pipeline not loaded.")
